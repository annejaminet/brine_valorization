{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "807e8f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anne/miniconda3/envs/watertap-flex/lib/python3.11/site-packages/seaborn/_statistics.py:32: UserWarning: A NumPy version >=1.23.5 and <2.3.0 is required for this version of SciPy (detected version 2.3.2)\n",
      "  from scipy.stats import gaussian_kde\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in df_ions: ['model_Ba_molL_frac', 'model_Ca_molL_frac', 'model_Fe_molL_frac', 'model_K_molL_frac', 'model_Li_molL_frac', 'model_Mg_molL_frac', 'model_Mn_molL_frac', 'model_Na_molL_frac', 'model_Sr_molL_frac', 'model_Br_molL_frac', 'model_Cl_molL_frac', 'model_C_molL_frac', 'model_SO4_molL_frac', 'model_B_molL_frac', 'model_Si_molL_frac', 'TDS_log10', 'well_depth_ft']\n",
      "DataFrame df_ions shape: (4733, 17)\n",
      "Columns in df_ion_si: ['model_Ba_molL_frac', 'model_Ca_molL_frac', 'model_Fe_molL_frac', 'model_K_molL_frac', 'model_Li_molL_frac', 'model_Mg_molL_frac', 'model_Mn_molL_frac', 'model_Na_molL_frac', 'model_Sr_molL_frac', 'model_Br_molL_frac', 'model_Cl_molL_frac', 'model_C_molL_frac', 'model_SO4_molL_frac', 'model_B_molL_frac', 'model_Si_molL_frac', 'TDS_log10', 'well_depth_ft', 'model_si_Calcite', 'model_si_Barite', 'model_si_Chalcedony', 'model_si_Gypsum']\n",
      "DataFrame df_ion_si shape: (4733, 21)\n",
      "Columns in df_ion_pp: ['model_Ba_molL_frac', 'model_Ca_molL_frac', 'model_Fe_molL_frac', 'model_K_molL_frac', 'model_Li_molL_frac', 'model_Mg_molL_frac', 'model_Mn_molL_frac', 'model_Na_molL_frac', 'model_Sr_molL_frac', 'model_Br_molL_frac', 'model_Cl_molL_frac', 'model_C_molL_frac', 'model_SO4_molL_frac', 'model_B_molL_frac', 'model_Si_molL_frac', 'TDS_log10', 'well_depth_ft', 'model_pp_Calcite_open_2x', 'model_pp_Calcite_open_4x', 'model_pp_Calcite_open_8x', 'model_pp_Barite_open_2x', 'model_pp_Barite_open_4x', 'model_pp_Barite_open_8x', 'model_pp_Chalcedony_open_2x', 'model_pp_Chalcedony_open_4x', 'model_pp_Chalcedony_open_8x', 'model_pp_Gypsum_open_2x', 'model_pp_Gypsum_open_4x', 'model_pp_Gypsum_open_8x']\n",
      "DataFrame df_ion_pp shape: (4733, 29)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1663598/503859769.py:20: DtypeWarning: Columns (5,9,29,56,62,68,76,92,98,107,146,166,170,183,186) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('data_states_processed.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import os\n",
    "import shutil\n",
    "from shapely.geometry import Point\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('data_states_processed.csv')\n",
    "#print(df.head())\n",
    "\n",
    "# Filter for wells with depth less than or equal to 3000 ft\n",
    "df = df[df['well_depth_ft'] <= 3000]\n",
    "\n",
    "# Define ions by group\n",
    "\n",
    "cations = ['model_Ba_molL', 'model_Ca_molL', 'model_Fe_molL', 'model_K_molL',\n",
    "           'model_Li_molL', 'model_Mg_molL', 'model_Mn_molL', 'model_Na_molL', 'model_Sr_molL']\n",
    "# Include Fe2+ as cation\n",
    "\n",
    "anions = ['model_Br_molL', 'model_Cl_molL', 'model_C_molL', 'model_SO4_molL']  # Treat model_C as HCO3-\n",
    "\n",
    "neutral_ions = ['model_B_molL', 'model_Si_molL']  # assumed neutral species\n",
    "\n",
    "# Charges dictionary for equivalent calculation (charge per mole)\n",
    "charges = {\n",
    "    'model_Ba_molL': 2,\n",
    "    'model_Ca_molL': 2,\n",
    "    'model_Fe_molL': 2,\n",
    "    'model_K_molL': 1,\n",
    "    'model_Li_molL': 1,\n",
    "    'model_Mg_molL': 2,\n",
    "    'model_Mn_molL': 2,\n",
    "    'model_Na_molL': 1,\n",
    "    'model_Sr_molL': 2,\n",
    "    'model_Br_molL': 1,\n",
    "    'model_Cl_molL': 1,\n",
    "    'model_C_molL': 1,\n",
    "    'model_SO4_molL': 2\n",
    "}\n",
    "\n",
    "# --- Calculate equivalents for cations and anions ---\n",
    "\n",
    "for ion in cations + anions:\n",
    "    df[ion + '_eq'] = df[ion] * charges[ion]\n",
    "\n",
    "# --- Calculate totals ---\n",
    "\n",
    "df['total_cations_eq'] = df[[c + '_eq' for c in cations]].sum(axis=1)\n",
    "df['total_anions_eq'] = df[[a + '_eq' for a in anions]].sum(axis=1)\n",
    "\n",
    "# Total ions in mol/L from all charged equivalents converted back to mol/L plus neutral ions\n",
    "    \n",
    "df['total_ion_molL'] = (\n",
    "    df[[ion + '_eq' for ion in cations + anions]].div(\n",
    "        [charges[i] for i in cations + anions], axis=1\n",
    "    ).sum(axis=1)\n",
    "    + df[neutral_ions].sum(axis=1)\n",
    ")\n",
    "\n",
    "# --- Calculate fractions ---\n",
    "\n",
    "# For ions belonging to cations and anions, fraction based on total equivalents\n",
    "for ion in cations:\n",
    "    df[ion + '_frac'] = np.where(df['total_cations_eq'] != 0,\n",
    "                                df[ion + '_eq'] / df['total_cations_eq'], \n",
    "                                np.nan)\n",
    "\n",
    "for ion in anions:\n",
    "    df[ion + '_frac'] = np.where(df['total_anions_eq'] != 0,\n",
    "                                df[ion + '_eq'] / df['total_anions_eq'], \n",
    "                                np.nan)\n",
    "\n",
    "# For neutral ions (B, Si), fraction based on total ions in mol/L (including neutral)\n",
    "for ion in neutral_ions:\n",
    "    df[ion + '_frac'] = np.where(df['total_ion_molL'] != 0,\n",
    "                                df[ion] / df['total_ion_molL'], \n",
    "                                np.nan)\n",
    "\n",
    "# --- Log10 transform TDS ---\n",
    "\n",
    "df['TDS_log10'] = np.log10(df['model_TDS_mgL'])\n",
    "\n",
    "# --- Select only requested columns in the new df_ions DataFrame ---\n",
    "\n",
    "frac_columns = [ion + '_frac' for ion in cations + anions + neutral_ions]\n",
    "selected_columns = frac_columns + ['TDS_log10'] + ['well_depth_ft']\n",
    "\n",
    "df_ions = df[selected_columns].copy()\n",
    "# Print columns of df_ions\n",
    "print(\"Columns in df_ions:\", df_ions.columns.tolist()) \n",
    "\n",
    "print(\"DataFrame df_ions shape:\", df_ions.shape)\n",
    "\n",
    "# Columns you want to add and standardize\n",
    "extra_si_cols = ['model_si_Calcite', 'model_si_Barite', 'model_si_Chalcedony', 'model_si_Gypsum']\n",
    "\n",
    "# Extract these columns from df\n",
    "df_extra = df[extra_si_cols].copy()\n",
    "\n",
    "# Combine df_ions and the standardized extra columns into df_ion_si\n",
    "df_ion_si = pd.concat([df_ions, df_extra], axis=1)\n",
    "\n",
    "print(\"Columns in df_ion_si:\", df_ion_si.columns.tolist()) \n",
    "\n",
    "print(\"DataFrame df_ion_si shape:\", df_ion_si.shape)\n",
    "\n",
    "# List of the new \"pp\" columns to add and standardize\n",
    "extra_pp_cols = [\n",
    "    'model_pp_Calcite_open_2x',\n",
    "    'model_pp_Calcite_open_4x',\n",
    "    'model_pp_Calcite_open_8x',\n",
    "    'model_pp_Barite_open_2x',\n",
    "    'model_pp_Barite_open_4x',\n",
    "    'model_pp_Barite_open_8x',\n",
    "    'model_pp_Chalcedony_open_2x',\n",
    "    'model_pp_Chalcedony_open_4x',\n",
    "    'model_pp_Chalcedony_open_8x',\n",
    "    'model_pp_Gypsum_open_2x',\n",
    "    'model_pp_Gypsum_open_4x',\n",
    "    'model_pp_Gypsum_open_8x'\n",
    "]\n",
    "\n",
    "# Extract these columns from df\n",
    "df_pp_extra = df[extra_pp_cols].copy()\n",
    "\n",
    "# Concatenate df_ions with the standardized pp columns to form df_ion_pp\n",
    "df_ion_pp = pd.concat([df_ions, df_pp_extra], axis=1)\n",
    "\n",
    "print(\"Columns in df_ion_pp:\", df_ion_pp.columns.tolist()) \n",
    "\n",
    "print(\"DataFrame df_ion_pp shape:\", df_ion_pp.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11b91704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CLUSTERING ACROSS ALL STATES ===\n",
      "All States, k=2, silhouette score=0.208\n",
      "All States, k=3, silhouette score=0.181\n",
      "All States, k=4, silhouette score=0.166\n",
      "All States, k=5, silhouette score=0.166\n",
      "All States, k=6, silhouette score=0.175\n",
      "All States, k=7, silhouette score=0.185\n",
      "All States, k=8, silhouette score=0.174\n",
      "All States, k=9, silhouette score=0.182\n",
      "All States, k=10, silhouette score=0.182\n",
      "All States, k=11, silhouette score=0.187\n",
      "All States, k=12, silhouette score=0.189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anne/miniconda3/envs/watertap-flex/lib/python3.11/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boxplots saved at: ion/Boxplots_by_Cluster_AllStates.png\n"
     ]
    }
   ],
   "source": [
    "########## ION CLUSTERING ##########\n",
    "##################################### which features are used the most for clustering? find out which features are most important for clustering\n",
    "\n",
    "state_col = 'state_alpha' \n",
    "output_folder = \"ion\"\n",
    "# 1. Clustering across all states together\n",
    "print(\"=== CLUSTERING ACROSS ALL STATES ===\")\n",
    "\n",
    "df_ions = df_ions.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "# remove well_depth_ft from df_ions\n",
    "df_cluster = df_ions.drop(columns=['well_depth_ft'], errors='ignore')\n",
    "\n",
    "\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "X_scaled_all = scaler.fit_transform(df_cluster)\n",
    "\n",
    "# Elbow method (R²)\n",
    "r2_values = []\n",
    "k_max = min(12, len(X_scaled_all) - 1)\n",
    "elbow_k_range = range(1, k_max+1)\n",
    "tot_ss = np.sum((X_scaled_all - X_scaled_all.mean(axis=0)) ** 2)\n",
    "for k in elbow_k_range:\n",
    "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    km.fit(X_scaled_all)\n",
    "    between_ss = tot_ss - km.inertia_\n",
    "    r2_values.append(between_ss / tot_ss)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(list(elbow_k_range), r2_values, marker='o')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('R²')\n",
    "plt.title('Elbow method for k-means: All States')\n",
    "elbow_path = os.path.join(output_folder, \"all_states_elbow.png\")\n",
    "plt.savefig(elbow_path, dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Silhouette method\n",
    "sil_scores = []\n",
    "sil_k_range = range(2, min(13, len(X_scaled_all)))\n",
    "for k in sil_k_range:\n",
    "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = km.fit_predict(X_scaled_all)\n",
    "    score = silhouette_score(X_scaled_all, labels)\n",
    "    sil_scores.append(score)\n",
    "    print(f\"All States, k={k}, silhouette score={score:.3f}\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(list(sil_k_range), sil_scores, marker='o')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Score vs k: All States')\n",
    "silhouette_path = os.path.join(output_folder, \"all_states_silhouette.png\")\n",
    "plt.savefig(silhouette_path, dpi=300)\n",
    "plt.close()\n",
    "\n",
    "\n",
    "########## CLUSTER ASSIGNMENT FOR ALL STATES ##########\n",
    "\n",
    "k_general = 3\n",
    "km = KMeans(n_clusters=k_general, random_state=42, n_init=10)\n",
    "cluster_labels = km.fit_predict(X_scaled_all)\n",
    "\n",
    "df_plot = df_ions.copy()\n",
    "df_plot['Cluster'] = cluster_labels.astype(str)  # String for plotting labels\n",
    "df_plot['model_Ba_molL_frac'] = np.log10(df_plot['model_Ba_molL_frac'])\n",
    "\n",
    "# 1. BOX PLOTS FOR EACH ION FEATURE BY CLUSTER\n",
    "cluster_counts = df_plot['Cluster'].value_counts().sort_index()\n",
    "# Make new labels in the form \"0\\n(n=73)\" etc.\n",
    "new_labels = [f\"{cl}\\n(n={cluster_counts[cl]})\" for cl in sorted(cluster_counts.index, key=lambda x: int(x))]\n",
    "\n",
    "# Make a copy of df_plot columns for plotting features\n",
    "plot_features = list(df_ions.columns)\n",
    "\n",
    "\n",
    "n_features = len(plot_features)\n",
    "n_cols = 3  \n",
    "n_rows = int(np.ceil(n_features / n_cols))\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(5 * n_cols, 4 * n_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, feature in enumerate(df_ions.columns):\n",
    "    ax = axes[idx]\n",
    "\n",
    "    if feature == \"model_Ba_molL_frac\":\n",
    "        df_filtered = df_plot[df_plot[feature] > 0].copy()\n",
    "        if len(df_filtered) > 0:\n",
    "            print(f\"Feature {feature} has {len(df_filtered)} valid points for log10 transformation.\")\n",
    "            df_filtered[feature + \"_log\"] = np.log10(df_filtered[feature])\n",
    "            do_log_plot = True\n",
    "\n",
    "            sns.boxplot(\n",
    "                x='Cluster',\n",
    "                y=feature + \"_log\",\n",
    "                data=df_filtered,\n",
    "                ax=ax,\n",
    "                order=sorted(cluster_counts.index, key=lambda x: int(x))\n",
    "            )\n",
    "            ax.set_title(f\"log10({feature}) by Cluster\")\n",
    "            ax.set_ylabel(f\"log10({feature})\")\n",
    "\n",
    "        else:\n",
    "            sns.boxplot(\n",
    "                x='Cluster',\n",
    "                y=feature,\n",
    "                data=df_plot,\n",
    "                ax=ax,\n",
    "                order=sorted(cluster_counts.index, key=lambda x: int(x))\n",
    "            )\n",
    "            ax.set_title(f\"{feature} by Cluster\")\n",
    "            ax.set_ylabel(feature)\n",
    "    else:\n",
    "        sns.boxplot(\n",
    "            x='Cluster',\n",
    "            y=feature,\n",
    "            data=df_plot,\n",
    "            ax=ax,\n",
    "            order=sorted(cluster_counts.index, key=lambda x: int(x))\n",
    "        )\n",
    "        ax.set_title(f\"{feature} by Cluster\")\n",
    "        ax.set_ylabel(feature)\n",
    "    ax.set_xlabel(\"Cluster\\n(sample count)\")\n",
    "    # Set new x-tick labels with sample sizes\n",
    "    tick_locs = range(len(new_labels))\n",
    "    ax.set_xticks(tick_locs)\n",
    "    ax.set_xticklabels(new_labels)\n",
    "for i in range(n_features, len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_folder, \"Boxplots_by_Cluster_AllStates.png\"), dpi=300)\n",
    "plt.close(fig)\n",
    "print(\"Boxplots saved at:\", os.path.join(output_folder, \"Boxplots_by_Cluster_AllStates.png\"))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e294dc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance plot saved at: ion/Feature_Importance_AllStates.png\n",
      "Within-cluster variance per cluster plot saved at: ion/Variance_Per_Feature_AllStates.png\n"
     ]
    }
   ],
   "source": [
    "################### FEATURE IMPORTANCE ###################\n",
    "\n",
    "centers = pd.DataFrame(km.cluster_centers_, columns=df_cluster.columns)\n",
    "# Feature importance: range (max-min) across cluster centers\n",
    "feature_importance = (centers.max(axis=0) - centers.min(axis=0)).sort_values(ascending=False)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "feature_importance.plot(kind='bar')\n",
    "plt.ylabel('Range across cluster centers (standardized)')\n",
    "plt.title('Feature Importance in Clustering')\n",
    "plt.tight_layout()\n",
    "importance_path = os.path.join(output_folder, \"Feature_Importance_AllStates.png\")\n",
    "plt.savefig(importance_path, dpi=300)\n",
    "plt.close()\n",
    "print(\"Feature importance plot saved at:\", importance_path)\n",
    "\n",
    "# Calculate within-cluster variance for each feature and each cluster\n",
    "variances = []\n",
    "cluster_ids = range(km.n_clusters)\n",
    "for cluster_id in cluster_ids:\n",
    "    cluster_data = df_cluster[cluster_labels == cluster_id]\n",
    "    cluster_variance = cluster_data.var(axis=0)\n",
    "    variances.append(cluster_variance)\n",
    "\n",
    "# Combine variances into a DataFrame, indexed by features, columns by cluster\n",
    "within_cluster_variance_df = pd.DataFrame(variances, index=[f\"Cluster {c}\" for c in cluster_ids]).T\n",
    "\n",
    "# Plot grouped bar chart of within-cluster variances\n",
    "fig, ax = plt.subplots(figsize=(15, 7))\n",
    "\n",
    "within_cluster_variance_df.plot(kind='bar', ax=ax)\n",
    "\n",
    "ax.set_ylabel('Variance (standardized units)')\n",
    "ax.set_title('Feature Variability Within Each Cluster')\n",
    "ax.legend(title='Cluster')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "\n",
    "variance_path = os.path.join(output_folder, \"Variance_Per_Feature_AllStates.png\")\n",
    "plt.savefig(variance_path, dpi=300)\n",
    "plt.close()\n",
    "\n",
    "print(f\"Within-cluster variance per cluster plot saved at: {variance_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "568a9427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered map saved at: ion/Clustered_Map_All_States.png\n"
     ]
    }
   ],
   "source": [
    "################### MAP CLUSTERS ####################\n",
    "import pyproj\n",
    "# Initialize 'cluster_ion' column in df as NaN or empty\n",
    "df['cluster_ion'] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "df_plot['dec_lat_va'] = df.loc[df_plot.index, 'dec_lat_va']\n",
    "df_plot['dec_long_va'] = df.loc[df_plot.index, 'dec_long_va']\n",
    "\n",
    "# Remove all NaN lat/long rows\n",
    "df_plot = df_plot.dropna(subset=['dec_lat_va', 'dec_long_va'])\n",
    "\n",
    "\n",
    "#gdf = lat_long_to_point(df_plot, lat_col='dec_lat_va', long_col='dec_long_va')\n",
    "df_geo = [Point(lon, lat) for lon, lat in zip(df_plot['dec_long_va'], df_plot['dec_lat_va'])]\n",
    "gdf = gpd.GeoDataFrame(df_plot, geometry=df_geo, crs='EPSG:4326')\n",
    "\n",
    "\n",
    "# Now plot coloring by cluster\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "gdf.plot(\n",
    "    ax=ax,\n",
    "    column='Cluster',\n",
    "    categorical=True,\n",
    "    legend=True,\n",
    "    cmap='tab10',   # Choose any categorical colormap\n",
    "    markersize=30\n",
    ")\n",
    "ax.set_title('Clustered Points Map - Across All States')\n",
    "ax.set_axis_off()\n",
    "# Save the map\n",
    "map_path = os.path.join(output_folder, \"Clustered_Map_All_States.png\")\n",
    "plt.savefig(map_path, dpi=300)\n",
    "plt.close()\n",
    "print(\"Clustered map saved at:\", map_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14d74a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = df['state_alpha'].unique()\n",
    "print(\"States found in the dataset:\", states)\n",
    "\n",
    "n_states = len(states)\n",
    "\n",
    "output_folder = \"ion\"\n",
    "\n",
    "# Create one figure for all elbow plots and one for all silhouette plots\n",
    "fig_elbow, axes_elbow = plt.subplots(n_states, 1, figsize=(7, 4 * n_states), constrained_layout=True)\n",
    "fig_sil, axes_sil = plt.subplots(n_states, 1, figsize=(7, 4 * n_states), constrained_layout=True)\n",
    "\n",
    "\n",
    "\n",
    "for idx, state in enumerate(states):\n",
    "    X_state = X_scaled_all[df['state_alpha'] == state]\n",
    "    print(f\"\\nState: {state}, Shape: {X_state.shape}\")\n",
    "\n",
    "    # Standardize per state\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_state)\n",
    "\n",
    "    # Elbow\n",
    "    r2_values = []\n",
    "    k_max = min(12, len(X_state) - 1)  # Note: use X_state!\n",
    "    elbow_k_range = range(1, k_max+1)\n",
    "    tot_ss = np.sum((X_scaled - X_scaled.mean(axis=0)) ** 2)\n",
    "    for k in elbow_k_range:\n",
    "        km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "        km.fit(X_scaled)\n",
    "        between_ss = tot_ss - km.inertia_\n",
    "        r2_values.append(between_ss / tot_ss)\n",
    "\n",
    "    axes_elbow[idx].plot(list(elbow_k_range), r2_values, marker='o')\n",
    "    axes_elbow[idx].set_xlabel('k')\n",
    "    axes_elbow[idx].set_ylabel('R²')\n",
    "    axes_elbow[idx].set_title(f'Elbow: {state}')\n",
    "\n",
    "    # Silhouette\n",
    "    sil_scores = []\n",
    "    sil_k_range = range(2, min(13, len(X_state)))  # Note: use X_state!\n",
    "    for k in sil_k_range:\n",
    "        km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "        labels = km.fit_predict(X_scaled)\n",
    "        score = silhouette_score(X_scaled, labels)\n",
    "        sil_scores.append(score)\n",
    "        print(f\"State={state}, k={k}, silhouette score={score:.3f}\")\n",
    "\n",
    "    axes_sil[idx].plot(list(sil_k_range), sil_scores, marker='o')\n",
    "    axes_sil[idx].set_xlabel('k')\n",
    "    axes_sil[idx].set_ylabel('Silhouette Score')\n",
    "    axes_sil[idx].set_title(f'Silhouette: {state}')\n",
    "\n",
    "# Save the combined figures\n",
    "fig_elbow.savefig(os.path.join(output_folder, \"states_elbow.png\"), dpi=300)\n",
    "fig_sil.savefig(os.path.join(output_folder, \"states_silhouette.png\"), dpi=300)\n",
    "plt.close(fig_elbow)\n",
    "plt.close(fig_sil)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b80b843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boxplots saved at: ion/Boxplots_by_Cluster_NM.png\n",
      "Number of cluster points: NM, k=3, Cluster labels shape: (159,)\n",
      "Cluster counts for NM: {np.int32(0): np.int64(106), np.int32(1): np.int64(50), np.int32(2): np.int64(3)}\n",
      "Feature importance plot saved at: ion/Feature_Importance_NM.png\n",
      "Within-cluster variance per cluster plot saved at: ion/Variance_Per_Feature_NM.png\n",
      "Clustered map saved at: ion/Clustered_Map_NM.png\n",
      "Feature model_Ba_molL_frac in state TX has 18 valid points for log10 transformation.\n",
      "Boxplots saved at: ion/Boxplots_by_Cluster_TX.png\n",
      "Number of cluster points: TX, k=6, Cluster labels shape: (2327,)\n",
      "Cluster counts for TX: {np.int32(0): np.int64(788), np.int32(1): np.int64(492), np.int32(2): np.int64(689), np.int32(3): np.int64(347), np.int32(4): np.int64(1), np.int32(5): np.int64(10)}\n",
      "Feature importance plot saved at: ion/Feature_Importance_TX.png\n",
      "Within-cluster variance per cluster plot saved at: ion/Variance_Per_Feature_TX.png\n",
      "Clustered map saved at: ion/Clustered_Map_TX.png\n",
      "Feature model_Ba_molL_frac in state FL has 1 valid points for log10 transformation.\n",
      "Boxplots saved at: ion/Boxplots_by_Cluster_FL.png\n",
      "Number of cluster points: FL, k=5, Cluster labels shape: (376,)\n",
      "Cluster counts for FL: {np.int32(0): np.int64(81), np.int32(1): np.int64(43), np.int32(2): np.int64(195), np.int32(3): np.int64(14), np.int32(4): np.int64(43)}\n",
      "Feature importance plot saved at: ion/Feature_Importance_FL.png\n",
      "Within-cluster variance per cluster plot saved at: ion/Variance_Per_Feature_FL.png\n",
      "Clustered map saved at: ion/Clustered_Map_FL.png\n",
      "Feature model_Ba_molL_frac in state CA has 3 valid points for log10 transformation.\n",
      "Boxplots saved at: ion/Boxplots_by_Cluster_CA.png\n",
      "Number of cluster points: CA, k=3, Cluster labels shape: (1266,)\n",
      "Cluster counts for CA: {np.int32(0): np.int64(700), np.int32(1): np.int64(102), np.int32(2): np.int64(464)}\n",
      "Feature importance plot saved at: ion/Feature_Importance_CA.png\n",
      "Within-cluster variance per cluster plot saved at: ion/Variance_Per_Feature_CA.png\n",
      "Clustered map saved at: ion/Clustered_Map_CA.png\n",
      "Feature model_Ba_molL_frac in state AZ has 2 valid points for log10 transformation.\n",
      "Boxplots saved at: ion/Boxplots_by_Cluster_AZ.png\n",
      "Number of cluster points: AZ, k=4, Cluster labels shape: (605,)\n",
      "Cluster counts for AZ: {np.int32(0): np.int64(23), np.int32(1): np.int64(547), np.int32(2): np.int64(11), np.int32(3): np.int64(24)}\n",
      "Feature importance plot saved at: ion/Feature_Importance_AZ.png\n",
      "Within-cluster variance per cluster plot saved at: ion/Variance_Per_Feature_AZ.png\n",
      "Clustered map saved at: ion/Clustered_Map_AZ.png\n"
     ]
    }
   ],
   "source": [
    "########## ION CLUSTERING BY STATE PART 2 ##########\n",
    "\n",
    "state_k_map = {\n",
    "    \"NM\": 3,\n",
    "    \"TX\": 6,\n",
    "    \"FL\": 5,\n",
    "    \"CA\": 3,\n",
    "    \"AZ\": 4\n",
    "}\n",
    "\n",
    "for state, k_state in state_k_map.items():\n",
    "    df_state = df_cluster[df['state_alpha'] == state].copy()\n",
    "    X_scaled_state = X_scaled_all[df['state_alpha'] == state]\n",
    "\n",
    "    # Cluster assignment\n",
    "    km_state = KMeans(n_clusters=k_state, random_state=42, n_init=10)\n",
    "    cluster_labels = km_state.fit_predict(X_scaled_state)\n",
    "    df_plot_state = df_ions[df['state_alpha'] == state].copy()\n",
    "    df_plot_state['Cluster'] = cluster_labels.astype(str)\n",
    "\n",
    "    # 1. BOX PLOTS FOR EACH ION FEATURE BY CLUSTER\n",
    "    cluster_counts = df_plot_state['Cluster'].value_counts().sort_index()\n",
    "    # Make new labels in the form \"0\\n(n=73)\" etc.\n",
    "    new_labels = [f\"{cl}\\n(n={cluster_counts[cl]})\" for cl in sorted(cluster_counts.index, key=lambda x: int(x))]\n",
    "\n",
    "    # Make a copy of df_plot columns for plotting features\n",
    "    plot_features = list(df_ions.columns)\n",
    "    \n",
    "    # Boxplot grid\n",
    "    n_features = len(df_ions.columns)\n",
    "    n_cols = 3\n",
    "    n_rows = int(np.ceil(n_features / n_cols))\n",
    "    \n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(5 * n_cols, 4 * n_rows))\n",
    "    axes = axes.flatten()\n",
    "    for idx, feature in enumerate(df_ions.columns):\n",
    "        ax = axes[idx]\n",
    "        # Add count of points in each cluster\n",
    "        if feature == \"model_Ba_molL_frac\":\n",
    "            # Plot log10 of the feature \"on the fly\" filtering out <= 0 values to avoid log errors\n",
    "            df_filtered = df_plot_state[df_plot_state[feature] > 0].copy()\n",
    "            if len(df_filtered) > 0:\n",
    "                print(f\"Feature {feature} in state {state} has {len(df_filtered)} valid points for log10 transformation.\")\n",
    "                df_filtered[feature + \"_log\"] = np.log10(df_filtered[feature])\n",
    "                do_log_plot = True\n",
    "\n",
    "                sns.boxplot(\n",
    "                    x='Cluster',\n",
    "                    y=feature + \"_log\",\n",
    "                    data=df_filtered,\n",
    "                    ax=ax,\n",
    "                    order=sorted(cluster_counts.index, key=lambda x: int(x))\n",
    "                )\n",
    "                ax.set_title(f\"log10({feature}) by Cluster\")\n",
    "                ax.set_ylabel(f\"log10({feature})\")\n",
    "\n",
    "            else:\n",
    "                sns.boxplot(\n",
    "                    x='Cluster',\n",
    "                    y=feature,\n",
    "                    data=df_plot_state,\n",
    "                    ax=ax,\n",
    "                    order=sorted(cluster_counts.index, key=lambda x: int(x))\n",
    "                )\n",
    "                ax.set_title(f\"{feature} by Cluster\")\n",
    "                ax.set_ylabel(feature)\n",
    "\n",
    "        else:\n",
    "            sns.boxplot(\n",
    "                x='Cluster',\n",
    "                y=feature,\n",
    "                data=df_plot_state,\n",
    "                ax=ax,\n",
    "                order=sorted(cluster_counts.index, key=lambda x: int(x))\n",
    "            )\n",
    "            ax.set_title(f\"{feature} by Cluster\")\n",
    "        #sns.boxplot(x='Cluster', y=feature, data=df_plot_state, ax=ax)\n",
    "\n",
    "        ax.set_xlabel(\"Cluster\\n(sample count)\")\n",
    "        # Explicitly set tick locations and labels to avoid warning\n",
    "        tick_locs = range(len(new_labels))\n",
    "        ax.set_xticks(tick_locs)\n",
    "        ax.set_xticklabels(new_labels)\n",
    "        \n",
    "    for i in range(n_features, len(axes)):\n",
    "        fig.delaxes(axes[i])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_folder, f\"Boxplots_by_Cluster_{state}.png\"), dpi=300)\n",
    "    plt.close(fig)\n",
    "    print(f\"Boxplots saved at: {output_folder}/Boxplots_by_Cluster_{state}.png\")\n",
    "    print(f\"Number of cluster points: {state}, k={k_state}, Cluster labels shape: {cluster_labels.shape}\")\n",
    "    # Print out number of points in each cluster\n",
    "    unique, counts = np.unique(cluster_labels, return_counts=True)\n",
    "    cluster_counts = dict(zip(unique, counts))\n",
    "    print(f\"Cluster counts for {state}: {cluster_counts}\")\n",
    "\n",
    "    centers = pd.DataFrame(km_state.cluster_centers_, columns=df_state.columns)\n",
    "    # Feature importance: range (max-min) across cluster centers\n",
    "    feature_importance = (centers.max(axis=0) - centers.min(axis=0)).sort_values(ascending=False)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    feature_importance.plot(kind='bar')\n",
    "    plt.ylabel('Range across cluster centers (standardized)')\n",
    "    plt.title(f'Feature Importance in Clustering for {state}')\n",
    "    plt.tight_layout()\n",
    "    importance_path = os.path.join(output_folder, f\"Feature_Importance_{state}.png\")\n",
    "    plt.savefig(importance_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(\"Feature importance plot saved at:\", importance_path)\n",
    "    # Calculate within-cluster variance for each feature and each cluster\n",
    "    variances = []\n",
    "    within_cluster_variance_df = pd.DataFrame()\n",
    "    cluster_ids = range(km_state.n_clusters)\n",
    "    for cluster_id in cluster_ids:\n",
    "        cluster_data = df_state[cluster_labels == cluster_id]\n",
    "        cluster_variance = cluster_data.var(axis=0)\n",
    "        variances.append(cluster_variance)\n",
    "\n",
    "    # Combine variances into a DataFrame, indexed by features, columns by cluster\n",
    "    within_cluster_variance_df = pd.DataFrame(variances, index=[f\"Cluster {c}\" for c in cluster_ids]).T\n",
    "\n",
    "    # Plot grouped bar chart of within-cluster variances\n",
    "    fig, ax = plt.subplots(figsize=(15, 7))\n",
    "\n",
    "    within_cluster_variance_df.plot(kind='bar', ax=ax)\n",
    "\n",
    "    ax.set_ylabel('Variance (standardized units)')\n",
    "    ax.set_title(f'Feature Variability Within Each Cluster - {state}')\n",
    "    ax.legend(title='Cluster')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    variance_path = os.path.join(output_folder,f\"Variance_Per_Feature_{state}.png\")\n",
    "    plt.savefig(variance_path, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Within-cluster variance per cluster plot saved at: {variance_path}\")\n",
    "\n",
    "    df_plot_state['dec_lat_va'] = df.loc[df[df['state_alpha'] == state].index, 'dec_lat_va']\n",
    "    df_plot_state['dec_long_va'] = df.loc[df[df['state_alpha'] == state].index, 'dec_long_va']\n",
    "\n",
    "    # Remove all NaN lat/long rows\n",
    "    df_plot_state = df_plot_state.dropna(subset=['dec_lat_va', 'dec_long_va'])\n",
    "\n",
    "\n",
    "    #gdf = lat_long_to_point(df_plot, lat_col='dec_lat_va', long_col='dec_long_va')\n",
    "    df_geo = [Point(lon, lat) for lon, lat in zip(df_plot_state['dec_long_va'], df_plot_state['dec_lat_va'])]\n",
    "    gdf = gpd.GeoDataFrame(df_plot_state, geometry=df_geo, crs='EPSG:4326')\n",
    "\n",
    "\n",
    "    # Now plot coloring by cluster\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    gdf.plot(\n",
    "        ax=ax,\n",
    "        column='Cluster',\n",
    "        categorical=True,\n",
    "        legend=True,\n",
    "        cmap='tab10',   # Choose any categorical colormap\n",
    "        markersize=30\n",
    "    )\n",
    "    ax.set_title(f'Clustered Points Map - {state}')\n",
    "    ax.set_axis_off()\n",
    "    # Save the map\n",
    "    map_path = os.path.join(output_folder, f\"Clustered_Map_{state}.png\")\n",
    "    plt.savefig(map_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(\"Clustered map saved at:\", map_path)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7284c742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All States (Ion+SI), k=2, silhouette score=0.181\n",
      "All States (Ion+SI), k=3, silhouette score=0.163\n",
      "All States (Ion+SI), k=4, silhouette score=0.152\n",
      "All States (Ion+SI), k=5, silhouette score=0.159\n",
      "All States (Ion+SI), k=6, silhouette score=0.155\n",
      "All States (Ion+SI), k=7, silhouette score=0.162\n",
      "All States (Ion+SI), k=8, silhouette score=0.142\n",
      "All States (Ion+SI), k=9, silhouette score=0.146\n",
      "All States (Ion+SI), k=10, silhouette score=0.150\n",
      "All States (Ion+SI), k=11, silhouette score=0.150\n",
      "All States (Ion+SI), k=12, silhouette score=0.150\n",
      "Feature model_Ba_molL_frac has 24 valid points for log10 transformation.\n",
      "Boxplots saved at: ion_si/Boxplots_by_Cluster_AllStates.png\n",
      "Feature importance plot saved at: ion_si/Feature_Importance_AllStates.png\n",
      "Within-cluster variance per cluster plot saved at: ion_si/Variance_Per_Feature_AllStates.png\n",
      "Clustered map saved at: ion_si/Clustered_Map_All_States.png\n"
     ]
    }
   ],
   "source": [
    "############### ION + SI CLUSTERING ACROSS ALL STATES ###############\n",
    "\n",
    "\n",
    "output_folder = \"ion_si\"\n",
    "\n",
    "# Prepare data across all states\n",
    "\n",
    "df_features = df_ion_si.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "# remove well_depth_ft from df_ions\n",
    "df_cluster = df_features.drop(columns=['well_depth_ft'], errors='ignore')\n",
    "\n",
    "\n",
    "X_all = df_cluster.values\n",
    "scaler = StandardScaler()\n",
    "X_scaled_all = scaler.fit_transform(X_all)\n",
    "\n",
    "# 1. Elbow method (R²)\n",
    "r2_values = []\n",
    "k_max = min(12, len(X_scaled_all) - 1)\n",
    "elbow_k_range = range(1, k_max+1)\n",
    "tot_ss = np.sum((X_scaled_all - X_scaled_all.mean(axis=0)) ** 2)\n",
    "for k in elbow_k_range:\n",
    "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    km.fit(X_scaled_all)\n",
    "    between_ss = tot_ss - km.inertia_\n",
    "    r2_values.append(between_ss / tot_ss)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(list(elbow_k_range), r2_values, marker='o')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('R²')\n",
    "plt.title('Elbow method for k-means: All States (Ion+SI)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_folder, \"Elbow_AllStates.png\"), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# 2. Silhouette method\n",
    "sil_scores = []\n",
    "sil_k_range = range(2, min(13, len(X_scaled_all)))\n",
    "for k in sil_k_range:\n",
    "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = km.fit_predict(X_scaled_all)\n",
    "    score = silhouette_score(X_scaled_all, labels)\n",
    "    sil_scores.append(score)\n",
    "    print(f\"All States (Ion+SI), k={k}, silhouette score={score:.3f}\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(list(sil_k_range), sil_scores, marker='o')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Score vs k: All States (Ion+SI)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_folder, \"Silhouette_AllStates.png\"), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "k_use = 3\n",
    "\n",
    "# 3. Final clustering and labeling for plotting\n",
    "km = KMeans(n_clusters=k_use, random_state=42, n_init=10)\n",
    "cluster_labels = km.fit_predict(X_scaled_all)\n",
    "df_plot = df_features.copy()\n",
    "df_plot['Cluster'] = cluster_labels.astype(str)\n",
    "\n",
    "# 4. Multi-panel boxplots of ion+SI by cluster\n",
    "n_features = len(df_ion_si.columns)\n",
    "n_cols = 3\n",
    "n_rows = int(np.ceil(n_features / n_cols))\n",
    "\n",
    "cluster_counts = df_plot['Cluster'].value_counts().sort_index()\n",
    "# Make new labels in the form \"0\\n(n=73)\" etc.\n",
    "new_labels = [f\"{cl}\\n(n={cluster_counts[cl]})\" for cl in sorted(cluster_counts.index, key=lambda x: int(x))]\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(5 * n_cols, 4 * n_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, feature in enumerate(df_ion_si.columns):\n",
    "    ax = axes[idx]\n",
    "    if feature == \"model_Ba_molL_frac\":\n",
    "        df_filtered = df_plot[df_plot[feature] > 0].copy()\n",
    "        if len(df_filtered) > 0:\n",
    "            print(f\"Feature {feature} has {len(df_filtered)} valid points for log10 transformation.\")\n",
    "            df_filtered[feature + \"_log\"] = np.log10(df_filtered[feature])\n",
    "            sns.boxplot(\n",
    "                x='Cluster',\n",
    "                y=feature + \"_log\",\n",
    "                data=df_filtered,\n",
    "                ax=ax,\n",
    "                order=sorted(cluster_counts.index, key=lambda x: int(x))\n",
    "            )\n",
    "            ax.set_title(f\"log10({feature}) by Cluster\")\n",
    "            ax.set_ylabel(f\"log10({feature})\")\n",
    "        else:\n",
    "            sns.boxplot(x='Cluster', y=feature, data=df_plot, ax=ax, order=sorted(cluster_counts.index, key=lambda x: int(x)))\n",
    "            ax.set_title(f\"{feature} by Cluster\")\n",
    "            ax.set_ylabel(feature)\n",
    "    else:\n",
    "        sns.boxplot(x='Cluster', y=feature, data=df_plot, ax=ax, order=sorted(cluster_counts.index, key=lambda x: int(x)))\n",
    "        ax.set_title(f\"{feature} by Cluster\")\n",
    "        ax.set_ylabel(feature)\n",
    "    ax.set_xlabel(\"Cluster\\n(sample count)\")   \n",
    "    # Explicitly set tick locations and labels to avoid warning\n",
    "    tick_locs = range(len(new_labels))\n",
    "    ax.set_xticks(tick_locs)\n",
    "    ax.set_xticklabels(new_labels)\n",
    "for i in range(n_features, len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_folder, \"Boxplots_by_Cluster_AllStates.png\"), dpi=300)\n",
    "plt.close(fig)\n",
    "print(\"Boxplots saved at:\", os.path.join(output_folder, \"Boxplots_by_Cluster_AllStates.png\"))\n",
    "\n",
    "centers = pd.DataFrame(km.cluster_centers_, columns=df_cluster.columns)\n",
    "# Feature importance: range (max-min) across cluster centers\n",
    "feature_importance = (centers.max(axis=0) - centers.min(axis=0)).sort_values(ascending=False)\n",
    "plt.figure(figsize=(10,5))\n",
    "feature_importance.plot(kind='bar')\n",
    "plt.ylabel('Range across cluster centers (standardized)')\n",
    "plt.title('Feature Importance in Clustering')\n",
    "plt.tight_layout()\n",
    "importance_path = os.path.join(output_folder, \"Feature_Importance_AllStates.png\")\n",
    "plt.savefig(importance_path, dpi=300)\n",
    "plt.close()\n",
    "print(\"Feature importance plot saved at:\", importance_path)\n",
    "\n",
    "# Calculate within-cluster variance for each feature and each cluster\n",
    "variances = []\n",
    "cluster_ids = range(km.n_clusters)\n",
    "for cluster_id in cluster_ids:\n",
    "    cluster_data = df_cluster[cluster_labels == cluster_id]\n",
    "    cluster_variance = cluster_data.var(axis=0)\n",
    "    variances.append(cluster_variance)\n",
    "\n",
    "# Combine variances into a DataFrame, indexed by features, columns by cluster\n",
    "within_cluster_variance_df = pd.DataFrame(variances, index=[f\"Cluster {c}\" for c in cluster_ids]).T\n",
    "\n",
    "# Plot grouped bar chart of within-cluster variances\n",
    "fig, ax = plt.subplots(figsize=(15, 7))\n",
    "\n",
    "within_cluster_variance_df.plot(kind='bar', ax=ax)\n",
    "\n",
    "ax.set_ylabel('Variance (standardized units)')\n",
    "ax.set_title('Feature Variability Within Each Cluster')\n",
    "ax.legend(title='Cluster')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "\n",
    "variance_path = os.path.join(output_folder, \"Variance_Per_Feature_AllStates.png\")\n",
    "plt.savefig(variance_path, dpi=300)\n",
    "plt.close()\n",
    "\n",
    "print(f\"Within-cluster variance per cluster plot saved at: {variance_path}\")\n",
    "\n",
    "\n",
    "# 5. Map of clustered points\n",
    "df_plot['dec_lat_va'] = df.loc[df_plot.index, 'dec_lat_va']\n",
    "df_plot['dec_long_va'] = df.loc[df_plot.index, 'dec_long_va']\n",
    "\n",
    "# Remove all NaN lat/long rows\n",
    "df_plot = df_plot.dropna(subset=['dec_lat_va', 'dec_long_va'])\n",
    "\n",
    "\n",
    "#gdf = lat_long_to_point(df_plot, lat_col='dec_lat_va', long_col='dec_long_va')\n",
    "df_geo = [Point(lon, lat) for lon, lat in zip(df_plot['dec_long_va'], df_plot['dec_lat_va'])]\n",
    "gdf = gpd.GeoDataFrame(df_plot, geometry=df_geo, crs='EPSG:4326')\n",
    "\n",
    "\n",
    "# Now plot coloring by cluster\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "gdf.plot(\n",
    "    ax=ax,\n",
    "    column='Cluster',\n",
    "    categorical=True,\n",
    "    legend=True,\n",
    "    cmap='tab10',   # Choose any categorical colormap\n",
    "    markersize=30\n",
    ")\n",
    "ax.set_title('Clustered Points Map - Across All States')\n",
    "ax.set_axis_off()\n",
    "# Save the map\n",
    "map_path = os.path.join(output_folder, \"Clustered_Map_All_States.png\")\n",
    "plt.savefig(map_path, dpi=300)\n",
    "plt.close()\n",
    "print(\"Clustered map saved at:\", map_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50a04bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### ION + SI CLUSTERING BY STATE PART 1 ###############\n",
    "n_states = len(states)\n",
    "elbow_fig, elbow_axes = plt.subplots(n_states, 1, figsize=(7, 4 * n_states), constrained_layout=True)\n",
    "sil_fig, sil_axes = plt.subplots(n_states, 1, figsize=(7, 4 * n_states), constrained_layout=True)\n",
    "\n",
    "plot_idx = 0\n",
    "for state in states:\n",
    "    # Prepare data for this state\n",
    "    df_state = df[df[state_col] == state][df_cluster.columns].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "    print(f\"\\n--- State: {state}, Shape: {df_state.shape} ---\")\n",
    "    if len(df_state) < 10:\n",
    "        print(f\"  Not enough samples, skipping.\")\n",
    "        continue\n",
    "\n",
    "    X = df_state.values\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "    # 1. Elbow method (R²)\n",
    "    r2_values = []\n",
    "    k_max = min(12, len(X_scaled) - 1)\n",
    "    elbow_k_range = range(1, k_max + 1)\n",
    "    tot_ss = np.sum((X_scaled - X_scaled.mean(axis=0)) ** 2)\n",
    "    for k in elbow_k_range:\n",
    "        km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "        km.fit(X_scaled)\n",
    "        between_ss = tot_ss - km.inertia_\n",
    "        r2_values.append(between_ss / tot_ss)\n",
    "\n",
    "    elbow_axes[plot_idx].plot(list(elbow_k_range), r2_values, marker='o')\n",
    "    elbow_axes[plot_idx].set_xlabel('k')\n",
    "    elbow_axes[plot_idx].set_ylabel('R²')\n",
    "    elbow_axes[plot_idx].set_title(f'Elbow: {state} (Ion+SI)')\n",
    "\n",
    "    # 2. Silhouette method\n",
    "    sil_scores = []\n",
    "    sil_k_range = range(2, min(13, len(X_scaled)))\n",
    "    for k in sil_k_range:\n",
    "        km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "        labels = km.fit_predict(X_scaled)\n",
    "        score = silhouette_score(X_scaled, labels)\n",
    "        sil_scores.append(score)\n",
    "        print(f\"  k={k}, silhouette score={score:.3f}\")\n",
    "\n",
    "    sil_axes[plot_idx].plot(list(sil_k_range), sil_scores, marker='o')\n",
    "    sil_axes[plot_idx].set_xlabel('k')\n",
    "    sil_axes[plot_idx].set_ylabel('Silhouette Score')\n",
    "    sil_axes[plot_idx].set_title(f'Silhouette: {state} (Ion+SI)')\n",
    "\n",
    "    plot_idx += 1\n",
    "\n",
    "# Save the combined figures\n",
    "elbow_fig.savefig(os.path.join(output_folder, \"elbow_states.png\"), dpi=300)\n",
    "sil_fig.savefig(os.path.join(output_folder, \"silhouette_states.png\"), dpi=300)\n",
    "plt.close(elbow_fig)\n",
    "plt.close(sil_fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2057a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing NM (k=4) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1663598/1014742658.py:25: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_plot = df_features[df['state_alpha'] == state].copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Boxplots saved at: ion_si/Boxplots_by_Cluster_NM.png\n",
      "Feature importance plot saved at: ion_si/Feature_Importance_NM.png\n",
      "Within-cluster variance per cluster plot saved at: ion_si/Variance_Per_Feature_NM.png\n",
      "Clustered map saved at: ion_si/Clustered_Map_NM.png\n",
      "\n",
      "--- Processing TX (k=5) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1663598/1014742658.py:25: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_plot = df_features[df['state_alpha'] == state].copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature model_Ba_molL_frac in state TX has 18 valid points for log10 transformation.\n",
      "  Boxplots saved at: ion_si/Boxplots_by_Cluster_TX.png\n",
      "Feature importance plot saved at: ion_si/Feature_Importance_TX.png\n",
      "Within-cluster variance per cluster plot saved at: ion_si/Variance_Per_Feature_TX.png\n",
      "Clustered map saved at: ion_si/Clustered_Map_TX.png\n",
      "\n",
      "--- Processing FL (k=4) ---\n",
      "Feature model_Ba_molL_frac in state FL has 1 valid points for log10 transformation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1663598/1014742658.py:25: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_plot = df_features[df['state_alpha'] == state].copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Boxplots saved at: ion_si/Boxplots_by_Cluster_FL.png\n",
      "Feature importance plot saved at: ion_si/Feature_Importance_FL.png\n",
      "Within-cluster variance per cluster plot saved at: ion_si/Variance_Per_Feature_FL.png\n",
      "Clustered map saved at: ion_si/Clustered_Map_FL.png\n",
      "\n",
      "--- Processing CA (k=4) ---\n",
      "Feature model_Ba_molL_frac in state CA has 3 valid points for log10 transformation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1663598/1014742658.py:25: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_plot = df_features[df['state_alpha'] == state].copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Boxplots saved at: ion_si/Boxplots_by_Cluster_CA.png\n",
      "Feature importance plot saved at: ion_si/Feature_Importance_CA.png\n",
      "Within-cluster variance per cluster plot saved at: ion_si/Variance_Per_Feature_CA.png\n",
      "Clustered map saved at: ion_si/Clustered_Map_CA.png\n",
      "\n",
      "--- Processing AZ (k=4) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1663598/1014742658.py:25: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_plot = df_features[df['state_alpha'] == state].copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature model_Ba_molL_frac in state AZ has 2 valid points for log10 transformation.\n",
      "  Boxplots saved at: ion_si/Boxplots_by_Cluster_AZ.png\n",
      "Feature importance plot saved at: ion_si/Feature_Importance_AZ.png\n",
      "Within-cluster variance per cluster plot saved at: ion_si/Variance_Per_Feature_AZ.png\n",
      "Clustered map saved at: ion_si/Clustered_Map_AZ.png\n"
     ]
    }
   ],
   "source": [
    "############### ION + SI CLUSTERING BY STATE PART 2 ###############\n",
    "\n",
    "state_k_map = {\n",
    "    'NM': 4,\n",
    "    'TX': 5,\n",
    "    'FL': 4,\n",
    "    'CA': 4,\n",
    "    'AZ': 4\n",
    "}\n",
    "\n",
    "for state, k_state in state_k_map.items():\n",
    "    print(f\"\\n--- Processing {state} (k={k_state}) ---\")\n",
    "    df_state = df[df[state_col] == state][df_cluster.columns].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    if len(df_state) < k_state:\n",
    "        print(f\"  Not enough samples for k={k_state}, skipping.\")\n",
    "        continue\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(df_state)\n",
    "\n",
    "    # Cluster assignment\n",
    "    km = KMeans(n_clusters=k_state, random_state=42, n_init=10)\n",
    "    cluster_labels = km.fit_predict(X_scaled)\n",
    "    df_plot = df_features[df['state_alpha'] == state].copy()\n",
    "    df_plot['Cluster'] = cluster_labels.astype(str)\n",
    "    cluster_counts = df_plot['Cluster'].value_counts().sort_index()\n",
    "    # Make new labels in the form \"0\\n(n=73)\" etc.\n",
    "    new_labels = [f\"{cl}\\n(n={cluster_counts[cl]})\" for cl in sorted(cluster_counts.index, key=lambda x: int(x))]\n",
    "    # Multi-panel boxplots of features by cluster\n",
    "    n_features = len(df_ion_si.columns)\n",
    "    n_cols = 3\n",
    "    n_rows = int(np.ceil(n_features / n_cols))\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(5 * n_cols, 4 * n_rows))\n",
    "    axes = axes.flatten()\n",
    "    for idx, feature in enumerate(df_ion_si.columns):\n",
    "        ax = axes[idx]\n",
    "        if feature == \"model_Ba_molL_frac\":\n",
    "            df_filtered = df_plot[df_plot[feature] > 0].copy()\n",
    "            if len(df_filtered) > 0:\n",
    "                print(f\"Feature {feature} in state {state} has {len(df_filtered)} valid points for log10 transformation.\")\n",
    "                df_filtered[feature + \"_log\"] = np.log10(df_filtered[feature])\n",
    "                sns.boxplot(\n",
    "                    x='Cluster',\n",
    "                    y=feature + \"_log\",\n",
    "                    data=df_filtered,\n",
    "                    ax=ax,\n",
    "                    order=sorted(cluster_counts.index, key=lambda x: int(x))\n",
    "                )\n",
    "                ax.set_title(f\"log10({feature}) by Cluster\")\n",
    "                ax.set_ylabel(f\"log10({feature})\")\n",
    "            else:\n",
    "                sns.boxplot(x='Cluster', y=feature, data=df_plot, ax=ax, order=sorted(cluster_counts.index, key=lambda x: int(x)))\n",
    "                ax.set_title(f\"{feature} by Cluster\")\n",
    "                ax.set_ylabel(feature)\n",
    "        else:\n",
    "            sns.boxplot(x='Cluster', y=feature, data=df_plot, ax=ax, order=sorted(cluster_counts.index, key=lambda x: int(x)))\n",
    "            ax.set_title(f\"{feature} by Cluster\")\n",
    "        ax.set_xlabel(\"Cluster\\n(sample count)\")\n",
    "        # Explicitly set tick locations and labels to avoid warning\n",
    "        tick_locs = range(len(new_labels))\n",
    "        ax.set_xticks(tick_locs)\n",
    "        ax.set_xticklabels(new_labels)\n",
    "    for i in range(n_features, len(axes)):\n",
    "        fig.delaxes(axes[i])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_folder, f\"Boxplots_by_Cluster_{state}.png\"), dpi=300)\n",
    "    plt.close(fig)\n",
    "    print(f\"  Boxplots saved at: {output_folder}/Boxplots_by_Cluster_{state}.png\")\n",
    "\n",
    "    centers = pd.DataFrame(km.cluster_centers_, columns=df_state.columns)\n",
    "    # Feature importance: range (max-min) across cluster centers\n",
    "    feature_importance = (centers.max(axis=0) - centers.min(axis=0)).sort_values(ascending=False)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    feature_importance.plot(kind='bar')\n",
    "    plt.ylabel('Range across cluster centers (standardized)')\n",
    "    plt.title(f'Feature Importance in Clustering for {state}')\n",
    "    plt.tight_layout()\n",
    "    importance_path = os.path.join(output_folder, f\"Feature_Importance_{state}.png\")\n",
    "    plt.savefig(importance_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(\"Feature importance plot saved at:\", importance_path)\n",
    "    \n",
    "    # Calculate within-cluster variance for each feature and each cluster\n",
    "    variances = []\n",
    "    within_cluster_variance_df = pd.DataFrame()\n",
    "    cluster_ids = range(km.n_clusters)\n",
    "    for cluster_id in cluster_ids:\n",
    "        cluster_data = df_state[cluster_labels == cluster_id]\n",
    "        cluster_variance = cluster_data.var(axis=0)\n",
    "        variances.append(cluster_variance)\n",
    "\n",
    "    # Combine variances into a DataFrame, indexed by features, columns by cluster\n",
    "    within_cluster_variance_df = pd.DataFrame(variances, index=[f\"Cluster {c}\" for c in cluster_ids]).T\n",
    "\n",
    "    # Plot grouped bar chart of within-cluster variances\n",
    "    fig, ax = plt.subplots(figsize=(15, 7))\n",
    "\n",
    "    within_cluster_variance_df.plot(kind='bar', ax=ax)\n",
    "\n",
    "    ax.set_ylabel('Variance (standardized units)')\n",
    "    ax.set_title(f'Feature Variability Within Each Cluster - {state}')\n",
    "    ax.legend(title='Cluster')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    variance_path = os.path.join(output_folder,f\"Variance_Per_Feature_{state}.png\")\n",
    "    plt.savefig(variance_path, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Within-cluster variance per cluster plot saved at: {variance_path}\")\n",
    "\n",
    "\n",
    "    df_plot['dec_lat_va'] = df.loc[df[df['state_alpha'] == state].index, 'dec_lat_va']\n",
    "    df_plot['dec_long_va'] = df.loc[df[df['state_alpha'] == state].index, 'dec_long_va']\n",
    "\n",
    "    # Remove all NaN lat/long rows\n",
    "    df_plot = df_plot.dropna(subset=['dec_lat_va', 'dec_long_va'])\n",
    "\n",
    "\n",
    "    #gdf = lat_long_to_point(df_plot, lat_col='dec_lat_va', long_col='dec_long_va')\n",
    "    df_geo = [Point(lon, lat) for lon, lat in zip(df_plot['dec_long_va'], df_plot['dec_lat_va'])]\n",
    "    gdf = gpd.GeoDataFrame(df_plot, geometry=df_geo, crs='EPSG:4326')\n",
    "\n",
    "\n",
    "    # Now plot coloring by cluster\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    gdf.plot(\n",
    "        ax=ax,\n",
    "        column='Cluster',\n",
    "        categorical=True,\n",
    "        legend=True,\n",
    "        cmap='tab10',   # Choose any categorical colormap\n",
    "        markersize=30\n",
    "    )\n",
    "    ax.set_title(f'Clustered Points Map - {state}')\n",
    "    ax.set_axis_off()\n",
    "    # Save the map\n",
    "    map_path = os.path.join(output_folder, f\"Clustered_Map_{state}.png\")\n",
    "    plt.savefig(map_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(\"Clustered map saved at:\", map_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f048070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All States (Ion+PP), k=2, silhouette score=0.177\n",
      "All States (Ion+PP), k=3, silhouette score=0.196\n",
      "All States (Ion+PP), k=4, silhouette score=0.197\n",
      "All States (Ion+PP), k=5, silhouette score=0.180\n",
      "All States (Ion+PP), k=6, silhouette score=0.179\n",
      "All States (Ion+PP), k=7, silhouette score=0.186\n",
      "All States (Ion+PP), k=8, silhouette score=0.159\n",
      "All States (Ion+PP), k=9, silhouette score=0.175\n",
      "All States (Ion+PP), k=10, silhouette score=0.163\n",
      "All States (Ion+PP), k=11, silhouette score=0.163\n",
      "All States (Ion+PP), k=12, silhouette score=0.190\n",
      "Feature model_Ba_molL_frac has 24 valid points for log10 transformation.\n",
      "Boxplots saved at: ion_pp/Boxplots_by_Cluster_AllStates.png\n",
      "Feature importance plot saved at: ion_pp/Feature_Importance_AllStates.png\n",
      "Within-cluster variance per cluster plot saved at: ion_pp/Variance_Per_Feature_AllStates.png\n",
      "Clustered map saved at: ion_pp/Clustered_Map_All_States.png\n"
     ]
    }
   ],
   "source": [
    "################# ION + PP CLUSTERING ACROSS ALL STATES ############\n",
    "\n",
    "output_folder = \"ion_pp\"\n",
    "\n",
    "# Prepare data across all states\n",
    "df_features = df_ion_pp.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "df_cluster = df_features.drop(columns=['well_depth_ft'], errors='ignore')\n",
    "\n",
    "X_all = df_cluster.values\n",
    "scaler = StandardScaler()\n",
    "X_scaled_all = scaler.fit_transform(X_all)\n",
    "\n",
    "# 1. Elbow method (R²)\n",
    "r2_values = []\n",
    "k_max = min(12, len(X_scaled_all) - 1)\n",
    "elbow_k_range = range(1, k_max + 1)\n",
    "tot_ss = np.sum((X_scaled_all - X_scaled_all.mean(axis=0)) ** 2)\n",
    "for k in elbow_k_range:\n",
    "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    km.fit(X_scaled_all)\n",
    "    between_ss = tot_ss - km.inertia_\n",
    "    r2_values.append(between_ss / tot_ss)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(list(elbow_k_range), r2_values, marker='o')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('R²')\n",
    "plt.title('Elbow method for k-means: All States (Ion+PP)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_folder, \"Elbow_AllStates.png\"), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# 2. Silhouette method\n",
    "sil_scores = []\n",
    "sil_k_range = range(2, min(13, len(X_scaled_all)))\n",
    "for k in sil_k_range:\n",
    "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = km.fit_predict(X_scaled_all)\n",
    "    score = silhouette_score(X_scaled_all, labels)\n",
    "    sil_scores.append(score)\n",
    "    print(f\"All States (Ion+PP), k={k}, silhouette score={score:.3f}\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(list(sil_k_range), sil_scores, marker='o')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Score vs k: All States (Ion+PP)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_folder, \"Silhouette_AllStates.png\"), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "k_use = 4\n",
    "\n",
    "# 3. Final clustering and labeling for plotting\n",
    "km = KMeans(n_clusters=k_use, random_state=42, n_init=10)\n",
    "cluster_labels = km.fit_predict(X_scaled_all)\n",
    "df_plot = df_features.copy()\n",
    "df_plot['Cluster'] = cluster_labels.astype(str)\n",
    "\n",
    "# 4. Multi-panel boxplots of ion+PP by cluster\n",
    "n_features = len(df_ion_pp.columns)\n",
    "n_cols = 3\n",
    "n_rows = int(np.ceil(n_features / n_cols))\n",
    "\n",
    "cluster_counts = df_plot['Cluster'].value_counts().sort_index()\n",
    "# Make new labels in the form \"0\\n(n=73)\" etc.\n",
    "new_labels = [f\"{cl}\\n(n={cluster_counts[cl]})\" for cl in sorted(cluster_counts.index, key=lambda x: int(x))]\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(5 * n_cols, 4 * n_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, feature in enumerate(df_ion_pp.columns):\n",
    "    ax = axes[idx]\n",
    "    if feature == \"model_Ba_molL_frac\":\n",
    "        df_filtered = df_plot[df_plot[feature] > 0].copy()\n",
    "        if len(df_filtered) > 0:\n",
    "            print(f\"Feature {feature} has {len(df_filtered)} valid points for log10 transformation.\")\n",
    "            df_filtered[feature + \"_log\"] = np.log10(df_filtered[feature])\n",
    "            sns.boxplot(\n",
    "                x='Cluster',\n",
    "                y=feature + \"_log\",\n",
    "                data=df_filtered,\n",
    "                ax=ax,\n",
    "                order=sorted(cluster_counts.index, key=lambda x: int(x))\n",
    "            )\n",
    "            ax.set_title(f\"log10({feature}) by Cluster\")\n",
    "            ax.set_ylabel(f\"log10({feature})\")\n",
    "        else:\n",
    "            sns.boxplot(x='Cluster', y=feature, data=df_plot, ax=ax, order=sorted(cluster_counts.index, key=lambda x: int(x)))\n",
    "            ax.set_title(f\"{feature} by Cluster\")\n",
    "            ax.set_ylabel(feature)\n",
    "    else:\n",
    "        sns.boxplot(x='Cluster', y=feature, data=df_plot, ax=ax, order=sorted(cluster_counts.index, key=lambda x: int(x)))\n",
    "        ax.set_title(f\"{feature} by Cluster\")\n",
    "        ax.set_ylabel(feature)\n",
    "    ax.set_xlabel(\"Cluster\\n(sample count)\")\n",
    "    # Explicitly set tick locations and labels to avoid warning\n",
    "    tick_locs = range(len(new_labels))\n",
    "    ax.set_xticks(tick_locs)\n",
    "    ax.set_xticklabels(new_labels)\n",
    "# Remove any unused axes\n",
    "for i in range(n_features, len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_folder, \"Boxplots_by_Cluster_AllStates.png\"), dpi=300)\n",
    "plt.close(fig)\n",
    "print(\"Boxplots saved at:\", os.path.join(output_folder, \"Boxplots_by_Cluster_AllStates.png\"))\n",
    "\n",
    "centers = pd.DataFrame(km.cluster_centers_, columns=df_cluster.columns)\n",
    "# Feature importance: range (max-min) across cluster centers\n",
    "feature_importance = (centers.max(axis=0) - centers.min(axis=0)).sort_values(ascending=False)\n",
    "plt.figure(figsize=(10,5))\n",
    "feature_importance.plot(kind='bar')\n",
    "plt.ylabel('Range across cluster centers (standardized)')\n",
    "plt.title('Feature Importance in Clustering')\n",
    "plt.tight_layout()\n",
    "importance_path = os.path.join(output_folder, \"Feature_Importance_AllStates.png\")\n",
    "plt.savefig(importance_path, dpi=300)\n",
    "plt.close()\n",
    "print(\"Feature importance plot saved at:\", importance_path)\n",
    "\n",
    "# Calculate within-cluster variance for each feature and each cluster\n",
    "variances = []\n",
    "cluster_ids = range(km.n_clusters)\n",
    "for cluster_id in cluster_ids:\n",
    "    cluster_data = df_cluster[cluster_labels == cluster_id]\n",
    "    cluster_variance = cluster_data.var(axis=0)\n",
    "    variances.append(cluster_variance)\n",
    "\n",
    "# Combine variances into a DataFrame, indexed by features, columns by cluster\n",
    "within_cluster_variance_df = pd.DataFrame(variances, index=[f\"Cluster {c}\" for c in cluster_ids]).T\n",
    "\n",
    "# Plot grouped bar chart of within-cluster variances\n",
    "fig, ax = plt.subplots(figsize=(15, 7))\n",
    "\n",
    "within_cluster_variance_df.plot(kind='bar', ax=ax)\n",
    "\n",
    "ax.set_ylabel('Variance (standardized units)')\n",
    "ax.set_title('Feature Variability Within Each Cluster')\n",
    "ax.legend(title='Cluster')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "\n",
    "variance_path = os.path.join(output_folder, \"Variance_Per_Feature_AllStates.png\")\n",
    "plt.savefig(variance_path, dpi=300)\n",
    "plt.close()\n",
    "\n",
    "print(f\"Within-cluster variance per cluster plot saved at: {variance_path}\")\n",
    "\n",
    "\n",
    "# 5. Map of clustered points\n",
    "df_plot['dec_lat_va'] = df.loc[df_plot.index, 'dec_lat_va']\n",
    "df_plot['dec_long_va'] = df.loc[df_plot.index, 'dec_long_va']\n",
    "\n",
    "# Remove all NaN lat/long rows\n",
    "df_plot = df_plot.dropna(subset=['dec_lat_va', 'dec_long_va'])\n",
    "\n",
    "\n",
    "#gdf = lat_long_to_point(df_plot, lat_col='dec_lat_va', long_col='dec_long_va')\n",
    "df_geo = [Point(lon, lat) for lon, lat in zip(df_plot['dec_long_va'], df_plot['dec_lat_va'])]\n",
    "gdf = gpd.GeoDataFrame(df_plot, geometry=df_geo, crs='EPSG:4326')\n",
    "\n",
    "\n",
    "# Now plot coloring by cluster\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "gdf.plot(\n",
    "    ax=ax,\n",
    "    column='Cluster',\n",
    "    categorical=True,\n",
    "    legend=True,\n",
    "    cmap='tab10',   # Choose any categorical colormap\n",
    "    markersize=30\n",
    ")\n",
    "ax.set_title('Clustered Points Map - Across All States')\n",
    "ax.set_axis_off()\n",
    "# Save the map\n",
    "map_path = os.path.join(output_folder, \"Clustered_Map_All_States.png\")\n",
    "plt.savefig(map_path, dpi=300)\n",
    "plt.close()\n",
    "print(\"Clustered map saved at:\", map_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958baff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### ION + PP CLUSTERING BY STATE PART 1 ###############\n",
    "\n",
    "output_folder = \"ion_pp\"\n",
    "\n",
    "n_states = len(states)\n",
    "elbow_fig, elbow_axes = plt.subplots(n_states, 1, figsize=(7, 4 * n_states), constrained_layout=True)\n",
    "sil_fig, sil_axes = plt.subplots(n_states, 1, figsize=(7, 4 * n_states), constrained_layout=True)\n",
    "\n",
    "\n",
    "plot_idx = 0\n",
    "for state in states:\n",
    "    df_state = df[df[state_col] == state][df_cluster.columns].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "    print(f\"\\n--- State: {state}, Shape: {df_state.shape} ---\")\n",
    "    if len(df_state) < 10:\n",
    "        print(f\"  Not enough samples, skipping.\")\n",
    "        continue\n",
    "\n",
    "    X = df_state.values\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "    # Elbow method (R²)\n",
    "    r2_values = []\n",
    "    k_max = min(12, len(X_scaled)-1)\n",
    "    elbow_k_range = range(1, k_max+1)\n",
    "    tot_ss = np.sum((X_scaled - X_scaled.mean(axis=0)) ** 2)\n",
    "    for k in elbow_k_range:\n",
    "        km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "        km.fit(X_scaled)\n",
    "        between_ss = tot_ss - km.inertia_\n",
    "        r2_values.append(between_ss / tot_ss)\n",
    "\n",
    "    elbow_axes[plot_idx].plot(list(elbow_k_range), r2_values, marker='o')\n",
    "    elbow_axes[plot_idx].set_xlabel('k')\n",
    "    elbow_axes[plot_idx].set_ylabel('R²')\n",
    "    elbow_axes[plot_idx].set_title(f'Elbow: {state} (Ion+PP)')\n",
    "\n",
    "    # Silhouette method\n",
    "    sil_scores = []\n",
    "    sil_k_range = range(2, min(13, len(X_scaled)))\n",
    "    for k in sil_k_range:\n",
    "        km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "        labels = km.fit_predict(X_scaled)\n",
    "        score = silhouette_score(X_scaled, labels)\n",
    "        sil_scores.append(score)\n",
    "        print(f\"  k={k}, silhouette score={score:.3f}\")\n",
    "\n",
    "    sil_axes[plot_idx].plot(list(sil_k_range), sil_scores, marker='o')\n",
    "    sil_axes[plot_idx].set_xlabel('k')\n",
    "    sil_axes[plot_idx].set_ylabel('Silhouette Score')\n",
    "    sil_axes[plot_idx].set_title(f'Silhouette: {state} (Ion+PP)')\n",
    "\n",
    "    plot_idx += 1\n",
    "\n",
    "\n",
    "# Save the combined figures\n",
    "elbow_fig.savefig(os.path.join(output_folder, \"elbow_states.png\"), dpi=300)\n",
    "sil_fig.savefig(os.path.join(output_folder, \"silhouette_states.png\"), dpi=300)\n",
    "plt.close(elbow_fig)\n",
    "plt.close(sil_fig)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c4b1de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing NM (k=6) ---\n",
      "  Boxplots saved at: ion_pp/Boxplots_by_Cluster_NM.png\n",
      "Feature importance plot saved at: ion_pp/Feature_Importance_NM.png\n",
      "Within-cluster variance per cluster plot saved at: ion_pp/Variance_Per_Feature_NM.png\n",
      "Clustered map saved at: ion_pp/Clustered_Map_NM.png\n",
      "\n",
      "--- Processing TX (k=4) ---\n",
      "Feature model_Ba_molL_frac in state TX has 18 valid points for log10 transformation.\n",
      "  Boxplots saved at: ion_pp/Boxplots_by_Cluster_TX.png\n",
      "Feature importance plot saved at: ion_pp/Feature_Importance_TX.png\n",
      "Within-cluster variance per cluster plot saved at: ion_pp/Variance_Per_Feature_TX.png\n",
      "Clustered map saved at: ion_pp/Clustered_Map_TX.png\n",
      "\n",
      "--- Processing FL (k=4) ---\n",
      "Feature model_Ba_molL_frac in state FL has 1 valid points for log10 transformation.\n",
      "  Boxplots saved at: ion_pp/Boxplots_by_Cluster_FL.png\n",
      "Feature importance plot saved at: ion_pp/Feature_Importance_FL.png\n",
      "Within-cluster variance per cluster plot saved at: ion_pp/Variance_Per_Feature_FL.png\n",
      "Clustered map saved at: ion_pp/Clustered_Map_FL.png\n",
      "\n",
      "--- Processing CA (k=5) ---\n",
      "Feature model_Ba_molL_frac in state CA has 3 valid points for log10 transformation.\n",
      "  Boxplots saved at: ion_pp/Boxplots_by_Cluster_CA.png\n",
      "Feature importance plot saved at: ion_pp/Feature_Importance_CA.png\n",
      "Within-cluster variance per cluster plot saved at: ion_pp/Variance_Per_Feature_CA.png\n",
      "Clustered map saved at: ion_pp/Clustered_Map_CA.png\n",
      "\n",
      "--- Processing AZ (k=3) ---\n",
      "Feature model_Ba_molL_frac in state AZ has 2 valid points for log10 transformation.\n",
      "  Boxplots saved at: ion_pp/Boxplots_by_Cluster_AZ.png\n",
      "Feature importance plot saved at: ion_pp/Feature_Importance_AZ.png\n",
      "Within-cluster variance per cluster plot saved at: ion_pp/Variance_Per_Feature_AZ.png\n",
      "Clustered map saved at: ion_pp/Clustered_Map_AZ.png\n"
     ]
    }
   ],
   "source": [
    "############### ION + PP CLUSTERING BY STATE PART 2 ###############\n",
    "\n",
    "output_folder = \"ion_pp\"\n",
    "\n",
    "state_k_map = {\n",
    "    'NM': 6,\n",
    "    'TX': 4,\n",
    "    'FL': 4,\n",
    "    'CA': 5,\n",
    "    'AZ': 3\n",
    "}\n",
    "\n",
    "for state, k_state in state_k_map.items():\n",
    "    print(f\"\\n--- Processing {state} (k={k_state}) ---\")\n",
    "    df_state = df[df[state_col] == state][df_cluster.columns].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    if len(df_state) < k_state:\n",
    "        print(f\"  Not enough samples for k={k_state}, skipping.\")\n",
    "        continue\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(df_state)\n",
    "\n",
    "    # Cluster assignment\n",
    "    km = KMeans(n_clusters=k_state, random_state=42, n_init=10)\n",
    "    cluster_labels = km.fit_predict(X_scaled)\n",
    "    df_plot = df_features[df['state_alpha'] == state].copy()\n",
    "    df_plot['Cluster'] = cluster_labels.astype(str)\n",
    "    cluster_counts = df_plot['Cluster'].value_counts().sort_index()\n",
    "    # Make new labels in the form \"0\\n(n=73)\" etc.\n",
    "    new_labels = [f\"{cl}\\n(n={cluster_counts[cl]})\" for cl in sorted(cluster_counts.index, key=lambda x: int(x))]\n",
    "\n",
    "    # Multi-panel boxplots of features by cluster\n",
    "    n_features = len(df_ion_pp.columns)\n",
    "    n_cols = 3\n",
    "    n_rows = int(np.ceil(n_features / n_cols))\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(5 * n_cols, 4 * n_rows))\n",
    "    axes = axes.flatten()\n",
    "    for idx, feature in enumerate(df_ion_pp.columns):\n",
    "        ax = axes[idx]\n",
    "        if feature == \"model_Ba_molL_frac\":\n",
    "            df_filtered = df_plot[df_plot[feature] > 0].copy()\n",
    "            if len(df_filtered) > 0:\n",
    "                print(f\"Feature {feature} in state {state} has {len(df_filtered)} valid points for log10 transformation.\")\n",
    "                df_filtered[feature + \"_log\"] = np.log10(df_filtered[feature])\n",
    "                sns.boxplot(\n",
    "                    x='Cluster',\n",
    "                    y=feature + \"_log\",\n",
    "                    data=df_filtered,\n",
    "                    ax=ax,\n",
    "                    order=sorted(cluster_counts.index, key=lambda x: int(x))\n",
    "                )\n",
    "                ax.set_title(f\"log10({feature}) by Cluster\")\n",
    "                ax.set_ylabel(f\"log10({feature})\")\n",
    "            else:\n",
    "                sns.boxplot(x='Cluster', y=feature, data=df_plot, ax=ax, order=sorted(cluster_counts.index, key=lambda x: int(x)))\n",
    "                ax.set_title(f\"{feature} by Cluster\")\n",
    "                ax.set_ylabel(feature)\n",
    "        else:\n",
    "            sns.boxplot(x='Cluster', y=feature, data=df_plot, ax=ax, order=sorted(cluster_counts.index, key=lambda x: int(x)))\n",
    "            ax.set_title(f\"{feature} by Cluster\")\n",
    "        ax.set_xlabel(\"Cluster\\n(sample count)\")\n",
    "        # Explicitly set tick locations and labels to avoid warning\n",
    "        tick_locs = range(len(new_labels))\n",
    "        ax.set_xticks(tick_locs)\n",
    "        ax.set_xticklabels(new_labels)\n",
    "    for i in range(n_features, len(axes)):\n",
    "        fig.delaxes(axes[i])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_folder, f\"Boxplots_by_Cluster_{state}.png\"), dpi=300)\n",
    "    plt.close(fig)\n",
    "    print(f\"  Boxplots saved at: {output_folder}/Boxplots_by_Cluster_{state}.png\")\n",
    "\n",
    "    centers = pd.DataFrame(km.cluster_centers_, columns=df_state.columns)\n",
    "    # Feature importance: range (max-min) across cluster centers\n",
    "    feature_importance = (centers.max(axis=0) - centers.min(axis=0)).sort_values(ascending=False)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    feature_importance.plot(kind='bar')\n",
    "    plt.ylabel('Range across cluster centers (standardized)')\n",
    "    plt.title(f'Feature Importance in Clustering for {state}')\n",
    "    plt.tight_layout()\n",
    "    importance_path = os.path.join(output_folder, f\"Feature_Importance_{state}.png\")\n",
    "    plt.savefig(importance_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(\"Feature importance plot saved at:\", importance_path)\n",
    "\n",
    "    # Calculate within-cluster variance for each feature and each cluster\n",
    "    variances = []\n",
    "    within_cluster_variance_df = pd.DataFrame()\n",
    "    cluster_ids = range(km.n_clusters)\n",
    "    for cluster_id in cluster_ids:\n",
    "        cluster_data = df_state[cluster_labels == cluster_id]\n",
    "        cluster_variance = cluster_data.var(axis=0)\n",
    "        variances.append(cluster_variance)\n",
    "\n",
    "    # Combine variances into a DataFrame, indexed by features, columns by cluster\n",
    "    within_cluster_variance_df = pd.DataFrame(variances, index=[f\"Cluster {c}\" for c in cluster_ids]).T\n",
    "\n",
    "    # Plot grouped bar chart of within-cluster variances\n",
    "    fig, ax = plt.subplots(figsize=(15, 7))\n",
    "\n",
    "    within_cluster_variance_df.plot(kind='bar', ax=ax)\n",
    "\n",
    "    ax.set_ylabel('Variance (standardized units)')\n",
    "    ax.set_title(f'Feature Variability Within Each Cluster - {state}')\n",
    "    ax.legend(title='Cluster')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    variance_path = os.path.join(output_folder,f\"Variance_Per_Feature_{state}.png\")\n",
    "    plt.savefig(variance_path, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Within-cluster variance per cluster plot saved at: {variance_path}\")\n",
    "  \n",
    "\n",
    "\n",
    "    df_plot['dec_lat_va'] = df.loc[df[df['state_alpha'] == state].index, 'dec_lat_va']\n",
    "    df_plot['dec_long_va'] = df.loc[df[df['state_alpha'] == state].index, 'dec_long_va']\n",
    "\n",
    "    # Remove all NaN lat/long rows\n",
    "    df_plot = df_plot.dropna(subset=['dec_lat_va', 'dec_long_va'])\n",
    "\n",
    "\n",
    "    #gdf = lat_long_to_point(df_plot, lat_col='dec_lat_va', long_col='dec_long_va')\n",
    "    df_geo = [Point(lon, lat) for lon, lat in zip(df_plot['dec_long_va'], df_plot['dec_lat_va'])]\n",
    "    gdf = gpd.GeoDataFrame(df_plot, geometry=df_geo, crs='EPSG:4326')\n",
    "\n",
    "\n",
    "    # Now plot coloring by cluster\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    gdf.plot(\n",
    "        ax=ax,\n",
    "        column='Cluster',\n",
    "        categorical=True,\n",
    "        legend=True,\n",
    "        cmap='tab10',   # Choose any categorical colormap\n",
    "        markersize=30\n",
    "    )\n",
    "    ax.set_title(f'Clustered Points Map - {state}')\n",
    "    ax.set_axis_off()\n",
    "    # Save the map\n",
    "    map_path = os.path.join(output_folder, f\"Clustered_Map_{state}.png\")\n",
    "    plt.savefig(map_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(\"Clustered map saved at:\", map_path)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "watertap-flex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
